"""
现有海量日志数据保存在一个超级大的文件中,改文件无法直接读入内存,要求从中提取某天访问百度次数最多的那个IP.
"""

"""
解决思路:
本题与9.2的解决思路是一模一样的,也是利用hash方法将文件变成多个小文件,然后遍历一下每一个小文件,找出其中出现次数最多的IP,
最后比较各个小文件中出现最多的IP,找出所有IP中出现最多次数的IP.该题唯一需要确定的是把一个大文件分成几个小文件比较合适.
以IPV4为例,由于一个IP地址占用32位,因此最多会有2^32=4G种取值情况.如果使用hash(IP)%1024值,那么把海量IP日志分别存储到1024个小文件中.
这样,每个小文件最多包含4M个IP地址.如果使用2048个小文件,那么每个文件会最多包含2M个IP地址.因此,这类题目应该根据内存大小来确定
划分的小文件数目。
总之,关键就是用hash法将大文件划分成小文件,然后依次对小文件进行内存读取,分析出出现次数最多的IP.
"""