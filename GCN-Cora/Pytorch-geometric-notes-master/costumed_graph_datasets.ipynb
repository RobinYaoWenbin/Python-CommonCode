{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the dataset\n",
    "    Note for creating own graph dataset using pytorch geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.utils as ut\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create two simulation datasets\n",
    "- 10 graphs and 30 nodes per graph with random edges connections\n",
    "- number of node feature = 3\n",
    "- number of edge feature = 1\n",
    "- node's classification and graph classification\n",
    "        Adj [num_graph, num_node, num_node] be the adjacent matrices (sparse)\n",
    "        node_feature [num_graph, num_node, num_node_feature]\n",
    "        edge_feature [num_graph, num_node, num_node] (sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 1. 1. 0.]] [[0.         0.72864219 0.         ... 0.         0.         0.        ]\n",
      " [0.79184669 0.         0.02333868 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.3352479  0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.697748   0.         ... 0.81314479 0.12877876 0.        ]] [[0.09237084 0.06075373 0.60419195]\n",
      " [0.96611632 0.50272131 0.05151523]\n",
      " [0.22121866 0.24479291 0.33785713]\n",
      " [0.04360338 0.9048927  0.51556394]\n",
      " [0.67093079 0.06717284 0.05411547]\n",
      " [0.58646777 0.88729601 0.528482  ]\n",
      " [0.87781917 0.81099127 0.07585379]\n",
      " [0.20195747 0.65771067 0.44350138]\n",
      " [0.29069981 0.41863386 0.44519965]\n",
      " [0.91055225 0.10345828 0.27973075]\n",
      " [0.53756482 0.69828693 0.63063729]\n",
      " [0.94164274 0.79560892 0.55707684]\n",
      " [0.21468269 0.45087423 0.69338224]\n",
      " [0.83796217 0.95973622 0.60545277]\n",
      " [0.52691937 0.01769192 0.07209907]\n",
      " [0.156105   0.05475993 0.40086324]\n",
      " [0.33687855 0.63735416 0.53566511]\n",
      " [0.59597076 0.4719772  0.27773715]\n",
      " [0.95282531 0.08640916 0.938891  ]\n",
      " [0.31123805 0.51266145 0.10884232]\n",
      " [0.07093107 0.42954545 0.74169738]\n",
      " [0.26936478 0.56234789 0.27865034]\n",
      " [0.38861306 0.90644632 0.85583963]\n",
      " [0.51601754 0.23810563 0.19318391]\n",
      " [0.95408735 0.2027166  0.80816831]\n",
      " [0.36897021 0.98565985 0.36815574]\n",
      " [0.35151662 0.63746363 0.96151681]\n",
      " [0.97620961 0.70720615 0.75460637]\n",
      " [0.56340218 0.75577574 0.85977965]\n",
      " [0.4860953  0.61986226 0.5373167 ]\n",
      " [0.56247061 0.89004791 0.35561683]\n",
      " [0.20818403 0.45628011 0.20808519]\n",
      " [0.49840043 0.90350811 0.61743352]\n",
      " [0.85543285 0.16619092 0.90087359]\n",
      " [0.60178716 0.03175979 0.63311896]\n",
      " [0.95139696 0.079167   0.58245613]\n",
      " [0.9154786  0.00969517 0.63091293]\n",
      " [0.47490229 0.34698932 0.62753649]\n",
      " [0.05270209 0.75306305 0.00447948]\n",
      " [0.30693574 0.50395864 0.37702225]\n",
      " [0.30747594 0.83083515 0.93483257]\n",
      " [0.87371268 0.52243131 0.88416418]\n",
      " [0.92086157 0.4092384  0.28344586]\n",
      " [0.09826521 0.47909192 0.94629692]\n",
      " [0.56090753 0.6675621  0.11288382]\n",
      " [0.14351966 0.46447326 0.9512648 ]\n",
      " [0.36078464 0.87748404 0.12028859]\n",
      " [0.61701721 0.60061298 0.85987475]\n",
      " [0.0033167  0.18993167 0.21968763]\n",
      " [0.94996609 0.15369366 0.03696235]]\n"
     ]
    }
   ],
   "source": [
    "num_graph = 10\n",
    "num_node = 50\n",
    "num_node_features = 3\n",
    "num_edge_features = 1\n",
    "\n",
    "Adj = np.random.rand(num_graph, num_node, num_node)\n",
    "Adj[Adj >= 0.8] = True\n",
    "Adj[Adj <= 0.8] = False\n",
    "node_feature = np.random.rand(num_graph, num_node, num_node_features)\n",
    "edge_feature = np.random.rand(num_graph, num_node, num_node) * Adj\n",
    "\n",
    "graph_label = np.random.rand(num_graph)\n",
    "graph_label[graph_label>0.5] = 1\n",
    "graph_label[graph_label<0.5] = 0\n",
    "graph_label = graph_label.astype(int)\n",
    "\n",
    "node_label = np. random.rand(num_graph, num_node)\n",
    "node_label[node_label>0.5] = 1\n",
    "node_label[node_label<0.5] = 0\n",
    "node_label = node_label.astype(int)\n",
    "\n",
    "print(Adj[0, :,:], edge_feature[0, :, :], node_feature[0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of node classification task InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeDatasetInMem(InMemoryDataset):\n",
    "    \"\"\"\n",
    "    node classification in one graph\n",
    "    Should define the mask for training, validation and test\n",
    "    \"\"\"\n",
    "    def __init__(self, root, num_train_per_class=15, num_val=10, num_test=10, transform=None, pre_transform=None):\n",
    "        self.num_train_per_class = num_train_per_class\n",
    "        self.num_val = num_val\n",
    "        self.num_test = num_test\n",
    "        super(NodeDatasetInMem, self).__init__(root,transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [r'.\\NodeDatasetInMem.dataset']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        num_train_per_class = self.num_train_per_class\n",
    "        num_val = self.num_val\n",
    "        num_test = self.num_test\n",
    "        #data_list = []  # node classification do not neet to define data_list just data (one graph)\n",
    "        i=0\n",
    "        source_nodes, target_nodes = np.nonzero(Adj[i, :, :])\n",
    "        source_nodes = source_nodes.reshape((1, -1))\n",
    "        target_nodes = target_nodes.reshape((1, -1))\n",
    "\n",
    "        edge_index = torch.tensor(np.concatenate((source_nodes, target_nodes), axis=0), dtype=torch.long) # edge_index should be long type\n",
    "\n",
    "        edge_weight = edge_feature[i, source_nodes, target_nodes]\n",
    "        edge_weight = torch.tensor(edge_weight.reshape((-1, num_edge_features)), dtype=torch.float) # edge_index should be float\n",
    "        type\n",
    "        train_mask = np.zeros((num_node,), dtype=bool)\n",
    "        val_mask = np.zeros((num_node,), dtype=bool)\n",
    "        test_mask = np.zeros((num_node,), dtype=bool)\n",
    "\n",
    "        label = node_label[i, :]\n",
    "        [org_class_0_ind] =  np.nonzero(label == 0) \n",
    "        org_class_0_ind = org_class_0_ind.reshape(-1)\n",
    "        perm_class_0_ind = org_class_0_ind[np.random.permutation(org_class_0_ind.shape[0])]\n",
    "\n",
    "        [org_class_1_ind] =  np.nonzero(label == 1) \n",
    "        org_class_1_ind = org_class_1_ind.reshape(-1)\n",
    "        perm_class_1_ind = org_class_1_ind[np.random.permutation(org_class_1_ind.shape[0])]\n",
    "\n",
    "\n",
    "        train_ind = np.concatenate((perm_class_0_ind[:num_train_per_class], perm_class_1_ind[:num_train_per_class]), axis=0)\n",
    "        train_mask[train_ind] = True\n",
    "\n",
    "        [remaining] = np.nonzero(~train_mask)\n",
    "        remaining = remaining.reshape(-1)\n",
    "\n",
    "        val_mask[remaining[:num_val]] = True\n",
    "        test_mask[remaining[num_val:num_val+num_test]] = True\n",
    "\n",
    "        train_mask = torch.tensor(train_mask, dtype=torch.bool) # mask should be long type\n",
    "        val_mask = torch.tensor(val_mask, dtype=torch.bool)\n",
    "        test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "\n",
    "        x = torch.tensor(node_feature[i, :, :], dtype=torch.float) \n",
    "        y = torch.tensor(node_label[i, :], dtype=torch.long) # y should be long type\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y, edge_attr=edge_weight, train_mask = train_mask, val_mask = val_mask, test_mask = test_mask)\n",
    "            \n",
    "        data, slices = self.collate([data])\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_node_InMem = NodeDatasetInMem(root='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_node_InMem[0].y)\n",
    "print(dataset_node_InMem[0].y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of graph classification task InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDatasetInMem(InMemoryDataset):\n",
    "    \"\"\"\n",
    "    Graph classification \n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(GraphDatasetInMem, self).__init__(root,transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [r'.\\GraphDatasetInMem.dataset']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        data_list = [] # graph classification need to define data_list for multiple graph\n",
    "        for i in range(num_graph):\n",
    "            source_nodes, target_nodes = np.nonzero(Adj[i, :, :])\n",
    "            source_nodes = source_nodes.reshape((1, -1))\n",
    "            target_nodes = target_nodes.reshape((1, -1))\n",
    "\n",
    "            edge_index = torch.tensor(np.concatenate((source_nodes, target_nodes), axis=0), dtype=torch.long) # edge_index should be long type\n",
    "\n",
    "            edge_weight = edge_feature[i, source_nodes, target_nodes]\n",
    "            edge_weight = torch.tensor(edge_weight.reshape((-1, num_edge_features)), dtype=torch.float) # edge_index should be float\n",
    "            type\n",
    "\n",
    "            x = torch.tensor(node_feature[i, :, :], dtype=torch.float) \n",
    "            \n",
    "            # y should be long type, graph label should not be a 0-dimesion tensor\n",
    "            # use [graph_label[i]] ranther than graph_label[i]\n",
    "            y = torch.tensor([graph_label[i]], dtype=torch.long) \n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, y=y, edge_attr=edge_weight)\n",
    "            data_list.append(data)\n",
    "            \n",
    "        data, slices = self.collate(data_list) # Here used to be [data] for one graph\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_graph_InMem = GraphDatasetInMem(root='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_attr=[504, 1], edge_index=[2, 504], x=[50, 3], y=[1])\n",
      "Data(edge_attr=[495, 1], edge_index=[2, 495], x=[50, 3], y=[1])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_graph_InMem[0])\n",
    "print(dataset_graph_InMem[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of node classification task Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from torch_geometric.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    node classification in one graph\n",
    "    Should define the mask for training, validation and test\n",
    "    \"\"\"\n",
    "    def __init__(self, root, num_train_per_class=15, num_val=10, num_test=10, transform=None, pre_transform=None):\n",
    "        self.num_train_per_class = num_train_per_class\n",
    "        self.num_val = num_val\n",
    "        self.num_test = num_test\n",
    "        super(NodeDataset, self).__init__(root,transform, pre_transform)\n",
    "        # Do not load the data and slices here\n",
    "        #self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [r'./NodeDataset_0.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        num_train_per_class = self.num_train_per_class\n",
    "        num_val = self.num_val\n",
    "        num_test = self.num_test\n",
    "        #data_list = []  # node classification do not neet to define data_list just data (one graph)\n",
    "        i=0\n",
    "        source_nodes, target_nodes = np.nonzero(Adj[i, :, :])\n",
    "        source_nodes = source_nodes.reshape((1, -1))\n",
    "        target_nodes = target_nodes.reshape((1, -1))\n",
    "\n",
    "        edge_index = torch.tensor(np.concatenate((source_nodes, target_nodes), axis=0), dtype=torch.long) # edge_index should be long type\n",
    "\n",
    "        edge_weight = edge_feature[i, source_nodes, target_nodes]\n",
    "        edge_weight = torch.tensor(edge_weight.reshape((-1, num_edge_features)), dtype=torch.float) # edge_index should be float\n",
    "        type\n",
    "        train_mask = np.zeros((num_node,), dtype=bool)\n",
    "        val_mask = np.zeros((num_node,), dtype=bool)\n",
    "        test_mask = np.zeros((num_node,), dtype=bool)\n",
    "\n",
    "        label = node_label[i, :]\n",
    "        [org_class_0_ind] =  np.nonzero(label == 0) \n",
    "        org_class_0_ind = org_class_0_ind.reshape(-1)\n",
    "        perm_class_0_ind = org_class_0_ind[np.random.permutation(org_class_0_ind.shape[0])]\n",
    "\n",
    "        [org_class_1_ind] =  np.nonzero(label == 1) \n",
    "        org_class_1_ind = org_class_1_ind.reshape(-1)\n",
    "        perm_class_1_ind = org_class_1_ind[np.random.permutation(org_class_1_ind.shape[0])]\n",
    "\n",
    "\n",
    "        train_ind = np.concatenate((perm_class_0_ind[:num_train_per_class], perm_class_1_ind[:num_train_per_class]), axis=0)\n",
    "        train_mask[train_ind] = True\n",
    "\n",
    "        [remaining] = np.nonzero(~train_mask)\n",
    "        remaining = remaining.reshape(-1)\n",
    "\n",
    "        val_mask[remaining[:num_val]] = True\n",
    "        test_mask[remaining[num_val:num_val+num_test]] = True\n",
    "\n",
    "        train_mask = torch.tensor(train_mask, dtype=torch.bool) # mask should be long type\n",
    "        val_mask = torch.tensor(val_mask, dtype=torch.bool)\n",
    "        test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "\n",
    "        x = torch.tensor(node_feature[i, :, :], dtype=torch.float) \n",
    "        y = torch.tensor(node_label[i, :], dtype=torch.long) # y should be long type\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y, edge_attr=edge_weight, train_mask = train_mask, val_mask = val_mask, test_mask = test_mask)\n",
    "        # Directly save the data in order as .pt form\n",
    "        torch.save(data, osp.join(self.processed_dir, 'NodeDataset_{}.pt'.format(i)))\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, 'NodeDataset_{}.pt'.format(idx)))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_node = NodeDataset(root='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[504, 1], edge_index=[2, 504], test_mask=[50], train_mask=[50], val_mask=[50], x=[50, 3], y=[50])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_node[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of graph classification task Dataset\n",
    "    save one graph per .pt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset_1(Dataset):\n",
    "    \"\"\"\n",
    "    Graph classification \n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(GraphDataset_1, self).__init__(root,transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [r'.\\GraphDataset1_0.pt', r'.\\GraphDataset1_1.pt', r'.\\GraphDataset1_2.pt', r'.\\GraphDataset1_3.pt', r'.\\GraphDataset1_4.pt', r'.\\GraphDataset1_5.pt', r'.\\GraphDataset1_6.pt', r'.\\GraphDataset1_7.pt', r'.\\GraphDataset1_8.pt', r'.\\GraphDataset1_9.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        #data_list = [] # graph classification need to define data_list for multiple graph\n",
    "        for i in range(num_graph):\n",
    "            source_nodes, target_nodes = np.nonzero(Adj[i, :, :])\n",
    "            source_nodes = source_nodes.reshape((1, -1))\n",
    "            target_nodes = target_nodes.reshape((1, -1))\n",
    "\n",
    "            edge_index = torch.tensor(np.concatenate((source_nodes, target_nodes), axis=0), dtype=torch.long) # edge_index should be long type\n",
    "\n",
    "            edge_weight = edge_feature[i, source_nodes, target_nodes]\n",
    "            edge_weight = torch.tensor(edge_weight.reshape((-1, num_edge_features)), dtype=torch.float) # edge_index should be float\n",
    "            type\n",
    "\n",
    "            x = torch.tensor(node_feature[i, :, :], dtype=torch.float) \n",
    "            \n",
    "            # y should be long type, graph label should not be a 0-dimesion tensor\n",
    "            # use [graph_label[i]] ranther than graph_label[i]\n",
    "            y = torch.tensor([graph_label[i]], dtype=torch.long) \n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, y=y, edge_attr=edge_weight)\n",
    "            #data_list.append(data)\n",
    "            # save one graph per time\n",
    "            torch.save(data, osp.join(self.processed_dir, 'graphDataset1_{}.pt'.format(i)))\n",
    "            \n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, 'graphDataset1_{}.pt'.format(idx)))\n",
    "        return data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset_graph_1 = GraphDataset_1(root='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_attr=[504, 1], edge_index=[2, 504], x=[50, 3], y=[1])\n",
      "Data(edge_attr=[495, 1], edge_index=[2, 495], x=[50, 3], y=[1])\n"
     ]
    }
   ],
   "source": [
    "print(dataset_graph_1[0])\n",
    "print(dataset_graph_1[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
